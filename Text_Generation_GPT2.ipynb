{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFkp81wZZq2m6FywJklLhA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zd341/GPT2-Text-Generation/blob/main/Text_Generation_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fCXrwPNHhXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198c4ed1-e269-42d1-86ff-b25549ef4dce"
      },
      "source": [
        "# Install transformers package.\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKjN_oxBHoCy"
      },
      "source": [
        "# Text Generation GPT2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oj_QpGPU0DQ"
      },
      "source": [
        "# Load GPT model and tokenizer \n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa2SUnKeQgrv"
      },
      "source": [
        "# Instantiate pre-trained tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "GPT2model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\",pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFAKqDDlJTbJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "b77b4962-d453-4c89-c2e8-016dfc307408"
      },
      "source": [
        "# Use decode function\n",
        "tokenizer.decode(tokenizer.eos_token_id)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|endoftext|>'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpVHOMTBSN74"
      },
      "source": [
        "# Create sentence and encode it using encoding developed using the tokenizer \n",
        "\n",
        "sentence = \"I like data science and machine learning\"\n",
        "\n",
        "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1jc_qIJbg1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "452b266d-1eb2-42e2-cbdb-fa747bef796c"
      },
      "source": [
        "# Testing the decode function to the input id\n",
        "tokenizer.decode(input_ids[0][1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' like'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ZPkWrKc8dC"
      },
      "source": [
        "## Generate and Decode Text \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W71YMvoddCIP"
      },
      "source": [
        "# Generate the text data\n",
        "output2 = GPT2model.generate(input_ids,max_length=500,num_beams=5,no_repeat_ngram_size=3,early_stopping=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "XuswfxwVitwD",
        "outputId": "f6d558a4-87be-4074-9568-e04baa74912e"
      },
      "source": [
        "# View text generated by GPT2\n",
        "tokenizer.decode(output2[0],skip_special_tokens=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I like data science and machine learning, but I'm not a data scientist. I don't have a PhD in data science or machine learning. I have a BS in computer science, and I've done a lot of data science work. But I've never done a data science job.\\n\\nI'm not going to tell you how to do data science. I'm just going to give you some tips on how to get started, and then I'm going to talk about some of the things you can do to improve your chances of getting a job doing data science in the future. So let's get started!\\n\\nWhat is data science?\\n\\nData science is the study of data. It's about understanding how data is collected, stored, analyzed, and visualized. Data science is also about how data can be used to make better decisions, and it's about how you can use that data to improve the lives of people around the world. So it's not just about figuring out how to use data to make more money, it's also about making better decisions about what to do with that data, how to make it useful, and how to share that data with the people who need it the most. So that's what data science is all about, and that's why it's so important to understand what it is and how it works, so that you can apply that knowledge to your own work, and to the work of your colleagues and the people you want to work with. And that's also why data science jobs are so hard to get, because there's so much data out there, and so many different ways to use it. So if you don't know what you're doing, you're going to have a hard time finding a job in the data science field, and you're also going to be competing against people who do know what they're doing. So you have to be really good at what you do to get the job, and the best way to do that is to learn as much as you can about data science, so you can get the most out of the data that you do have, and use it to make the best decisions you can, and share that information with people who can use it the best. So here are a few things you should know before you start your data science career:\\n\\nKnowledge is power\\n\\nThe first thing you need to know is that knowledge is power. You don't need to be an expert\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}